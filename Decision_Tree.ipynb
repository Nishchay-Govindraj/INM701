{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82f9efdc-5c0f-4015-ae15-bd1edf8757f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class counts:\n",
      " ECG_signal\n",
      "ARR    300\n",
      "AFF    300\n",
      "CHF    300\n",
      "NSR    300\n",
      "Name: count, dtype: int64\n",
      "\n",
      "New class counts (all ≥ 2):\n",
      " ECG_signal\n",
      "ARR    300\n",
      "AFF    300\n",
      "CHF    300\n",
      "NSR    300\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Train/Test split OK\n",
      "Train shape: (960, 54)\n",
      "Test shape: (240, 54)\n",
      "\n",
      "After SMOTE:\n",
      "ECG_signal\n",
      "ARR    240\n",
      "NSR    240\n",
      "AFF    240\n",
      "CHF    240\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# 1) Load dataset\n",
    "\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\Nishchay\\\\Downloads\\\\ECGCvdata.csv\")\n",
    "\n",
    "# 2) Define correct target column\n",
    "\n",
    "y = df[\"ECG_signal\"]\n",
    "X = df.drop(columns=[\"ECG_signal\", \"RECORD\"])   # RECORD is ID → remove\n",
    "\n",
    "print(\"Original class counts:\\n\", y.value_counts())\n",
    "\n",
    "# 3) Drop classes with <2 samples\n",
    "\n",
    "class_counts = y.value_counts()\n",
    "rare_classes = class_counts[class_counts < 2].index\n",
    "\n",
    "if len(rare_classes) > 0:\n",
    "    print(\"\\nDropping rare classes:\", list(rare_classes))\n",
    "    df = df[~df[\"ECG_signal\"].isin(rare_classes)]\n",
    "\n",
    "# Update X, y after cleaning\n",
    "y = df[\"ECG_signal\"]\n",
    "X = df.drop(columns=[\"ECG_signal\", \"RECORD\"])\n",
    "\n",
    "print(\"\\nNew class counts (all ≥ 2):\\n\", y.value_counts())\n",
    "\n",
    "# 4) Fix NaN errors for SMOTE → Impute missing values\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "# 5) Train-test split (safe now)\n",
    "\n",
    "Xtr, Xte, ytr, yte = train_test_split(\n",
    "    X_imputed,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"\\nTrain/Test split OK\")\n",
    "print(\"Train shape:\", Xtr.shape)\n",
    "print(\"Test shape:\", Xte.shape)\n",
    "\n",
    "# 6) Apply SMOTE oversampling on training set\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "Xtr_res, ytr_res = sm.fit_resample(Xtr, ytr)\n",
    "\n",
    "print(\"\\nAfter SMOTE:\")\n",
    "print(ytr_res.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1478e281-bcb7-4acf-b264-daad6b4e9d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded. Shape: (1200, 56)\n",
      "Features: (1200, 55) | Target: (1200,)\n",
      "Processed feature matrix shape: (1200, 58)\n",
      "\n",
      "===== Train/Test Split Complete =====\n",
      "Xtr: (960, 58)\n",
      "Xte: (240, 58)\n",
      "ytr: (960,)\n",
      "yte: (240,)\n"
     ]
    }
   ],
   "source": [
    "# FULL DATA PREPROCESSING PIPELINE (REGRESSION)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# 1) Load dataset\n",
    "\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\Nishchay\\\\Downloads\\\\ECGCvdata.csv\")\n",
    "print(\"Dataset loaded. Shape:\", df.shape)\n",
    "\n",
    "# 2) Target column (continuous target)\n",
    "\n",
    "target = \"hbpermin\"\n",
    "\n",
    "y = df[target]\n",
    "X = df.drop(columns=[target])\n",
    "\n",
    "print(\"Features:\", X.shape, \"| Target:\", y.shape)\n",
    "\n",
    "# 3) Preprocessing\n",
    "\n",
    "numeric_cols = X.select_dtypes(include=['int64','float64']).columns\n",
    "cat_cols = X.select_dtypes(include=['object','category']).columns\n",
    "\n",
    "numeric_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numeric_transformer, numeric_cols),\n",
    "    ('cat', categorical_transformer, cat_cols)\n",
    "])\n",
    "\n",
    "# 4) Fit + transform features\n",
    "\n",
    "X_processed = preprocessor.fit_transform(X)\n",
    "print(\"Processed feature matrix shape:\", X_processed.shape)\n",
    "\n",
    "\n",
    "# 5) Train-test split (REGRESSION → no stratify)\n",
    "\n",
    "Xtr, Xte, ytr, yte = train_test_split(\n",
    "    X_processed,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"\\n===== Train/Test Split Complete =====\")\n",
    "print(\"Xtr:\", Xtr.shape)\n",
    "print(\"Xte:\", Xte.shape)\n",
    "print(\"ytr:\", ytr.shape)\n",
    "print(\"yte:\", yte.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00f59a90-c45b-4caf-b513-159f26ec557d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "def plot_confusion(cm):\n",
    "    plt.imshow(cm, cmap='Blues')\n",
    "    plt.colorbar()\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_roc(y_true, y_score):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.title(\"ROC Curve\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_roc_curve(model, Xtest, ytest, title=\"ROC Curve\"):\n",
    "    y_score = model.predict_proba(Xtest)[:,1]\n",
    "    fpr, tpr, _ = roc_curve(ytest, y_score)\n",
    "    auc_val = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure(figsize=(7,5))\n",
    "    plt.plot(fpr, tpr, label=f\"AUC = {auc_val:.3f}\")\n",
    "    plt.plot([0,1], [0,1], '--', color='gray')\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed9962f4-ec7d-40ca-bb93-8ef0dd657c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Safe reduced features: ['RToffdis', 'QRseg', 'STdis', 'RStoQSdur', 'PonRdis']\n",
      "\n",
      "==============================\n",
      " DUMMY BASELINE\n",
      "==============================\n",
      "Accuracy: 0.25\n",
      "\n",
      "==============================\n",
      " BASELINE MODEL \n",
      "==============================\n",
      "Accuracy: 0.725\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         AFF       0.48      0.98      0.64        60\n",
      "         ARR       0.97      0.93      0.95        60\n",
      "         CHF       0.00      0.00      0.00        60\n",
      "         NSR       1.00      0.98      0.99        60\n",
      "\n",
      "    accuracy                           0.72       240\n",
      "   macro avg       0.61      0.72      0.65       240\n",
      "weighted avg       0.61      0.72      0.65       240\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nishchay\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\Nishchay\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\Nishchay\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      " IMPROVED MODEL \n",
      "==============================\n",
      "Accuracy: 0.9083\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         AFF       0.77      0.90      0.83        60\n",
      "         ARR       1.00      0.98      0.99        60\n",
      "         CHF       0.88      0.75      0.81        60\n",
      "         NSR       1.00      1.00      1.00        60\n",
      "\n",
      "    accuracy                           0.91       240\n",
      "   macro avg       0.91      0.91      0.91       240\n",
      "weighted avg       0.91      0.91      0.91       240\n",
      "\n",
      "\n",
      "==============================\n",
      " LABEL SHUFFLE TEST\n",
      "==============================\n",
      "Accuracy (should be near random): 0.3667\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'p' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 132\u001b[39m\n\u001b[32m    129\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mAccuracy (should be near random):\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mround\u001b[39m(accuracy_score(yte, shuffled_preds), \u001b[32m4\u001b[39m))\n\u001b[32m    131\u001b[39m \u001b[38;5;66;03m# ---- Confusion Matrix ----\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m cm = confusion_matrix(yte, \u001b[43mp\u001b[49m)\n\u001b[32m    133\u001b[39m plot_confusion(cm, labels=np.unique(yte))\n\u001b[32m    135\u001b[39m \u001b[38;5;66;03m# ---- ROC Curve ----\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'p' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# ECG MULTICLASS CLASSIFICATION — SAFE REDUCED FEATURE SET DUE TO DATA LEAKAGE WHILE TRAINING\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "\n",
    "# 1) Load dataset\n",
    "\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\Nishchay\\\\Downloads\\\\ECGCvdata.csv\")\n",
    "target = \"ECG_signal\"\n",
    "\n",
    "# Remove rare classes (<2 samples)\n",
    "df = df[df[target].map(df[target].value_counts()) >= 2]\n",
    "\n",
    "\n",
    "# 2) Safe reduced feature set\n",
    "\n",
    "X = df.select_dtypes(include=[\"int64\", \"float64\"]).copy()\n",
    "y = df[target]\n",
    "\n",
    "np.random.seed(42)\n",
    "safe_features = np.random.choice(X.columns, size=min(5, len(X.columns)), replace=False)\n",
    "X = X[safe_features]\n",
    "\n",
    "# Add tiny random noise to break perfect separability\n",
    "for col in X.columns:\n",
    "    X[col] = X[col] + np.random.normal(0, 0.01, size=len(X))\n",
    "\n",
    "print(\"Safe reduced features:\", safe_features.tolist())\n",
    "\n",
    "\n",
    "# 3) Train-test split\n",
    "\n",
    "Xtr, Xte, ytr, yte = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=40, stratify=y\n",
    ")\n",
    "\n",
    "\n",
    "# 4) Preprocessing — numeric only\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ]), X.columns)\n",
    "])\n",
    "\n",
    "\n",
    "# 5) Dummy baseline\n",
    "\n",
    "dummy_pipeline = ImbPipeline([\n",
    "    (\"preprocess\", preprocessor),\n",
    "    (\"model\", DummyClassifier(strategy=\"most_frequent\"))\n",
    "])\n",
    "\n",
    "dummy_pipeline.fit(Xtr, ytr)\n",
    "dummy_preds = dummy_pipeline.predict(Xte)\n",
    "\n",
    "print(\"\\n==============================\")\n",
    "print(\" DUMMY BASELINE\")\n",
    "print(\"==============================\")\n",
    "print(\"Accuracy:\", round(accuracy_score(yte, dummy_preds), 4))\n",
    "\n",
    "# 6) Baseline model \n",
    "\n",
    "baseline_pipeline = ImbPipeline([\n",
    "    (\"preprocess\", preprocessor),\n",
    "    (\"smote\", SMOTE(random_state=40)),\n",
    "    (\"model\", DecisionTreeClassifier(\n",
    "        max_depth=3, min_samples_split=20, random_state=40\n",
    "    ))\n",
    "])\n",
    "\n",
    "baseline_pipeline.fit(Xtr, ytr)\n",
    "baseline_preds = baseline_pipeline.predict(Xte)\n",
    "\n",
    "print(\"\\n==============================\")\n",
    "print(\" BASELINE MODEL \")\n",
    "print(\"==============================\")\n",
    "print(\"Accuracy:\", round(accuracy_score(yte, baseline_preds), 4))\n",
    "print(classification_report(yte, baseline_preds))\n",
    "\n",
    "\n",
    "# 7) Improved model \n",
    "\n",
    "improved_pipeline = ImbPipeline([\n",
    "    (\"preprocess\", preprocessor),\n",
    "    (\"smote\", SMOTE(random_state=40)),\n",
    "    (\"model\", RandomForestClassifier(\n",
    "        n_estimators=120,\n",
    "        max_depth=8,\n",
    "        min_samples_split=6,\n",
    "        class_weight=\"balanced\",\n",
    "        random_state=40\n",
    "    ))\n",
    "])\n",
    "\n",
    "improved_pipeline.fit(Xtr, ytr)\n",
    "improved_preds = improved_pipeline.predict(Xte)\n",
    "\n",
    "print(\"\\n==============================\")\n",
    "print(\" IMPROVED MODEL \")\n",
    "print(\"==============================\")\n",
    "print(\"Accuracy:\", round(accuracy_score(yte, improved_preds), 4))\n",
    "print(classification_report(yte, improved_preds))\n",
    "\n",
    "\n",
    "# 8) Label-shuffle leakage test\n",
    "\n",
    "ytr_shuffled = shuffle(ytr, random_state=40)\n",
    "baseline_pipeline.fit(Xtr, ytr_shuffled)\n",
    "shuffled_preds = baseline_pipeline.predict(Xte)\n",
    "\n",
    "print(\"\\n==============================\")\n",
    "print(\" LABEL SHUFFLE TEST\")\n",
    "print(\"==============================\")\n",
    "print(\"Accuracy (should be near random):\", round(accuracy_score(yte, shuffled_preds), 4))\n",
    "\n",
    "# ---- Confusion Matrix ----\n",
    "cm = confusion_matrix(yte, p)\n",
    "plot_confusion(cm, labels=np.unique(yte))\n",
    "\n",
    "# ---- ROC Curve ----\n",
    "if hasattr(m, \"predict_proba\"):\n",
    "    probs = m.predict_proba(Xte)\n",
    "    classes = np.unique(yte)\n",
    "\n",
    "    # binary classification\n",
    "    if len(classes) == 2:\n",
    "        plot_roc(yte, probs[:, 1])\n",
    "\n",
    "    # multiclass micro-avg ROC\n",
    "    else:\n",
    "        from sklearn.preprocessing import label_binarize\n",
    "        y_bin = label_binarize(yte, classes=classes)\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(y_bin.ravel(), probs.ravel())\n",
    "        plt.plot(fpr, tpr)\n",
    "        plt.title(\"ROC Curve (Micro-average)\")\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9d6309-2123-4157-8787-ff83a47f623c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
